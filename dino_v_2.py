# -*- coding: utf-8 -*-
"""dino_v_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uDol0bQ1YXo6C1_SFmR7CK1ImuEcToM0
"""

!nvidia-smi

!git clone https://github.com/IDEA-Research/GroundingDINO.git

!pip install -q torch torchvision transformers timm supervision pycocotools opencv-python

import sys
import os
sys.path.append("/content/GroundingDINO")

!pip install addict

!pip install yapf

from groundingdino.util.inference import load_model, load_image, predict
print("GroundingDINO imported successfully!")

CONFIG_PATH = "GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py"
print(CONFIG_PATH, "; exist:", os.path.isfile(CONFIG_PATH))

!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth

WEIGHTS_PATH = "groundingdino_swint_ogc.pth"
print(WEIGHTS_PATH, "; exist:", os.path.isfile(WEIGHTS_PATH))

from groundingdino.util.inference import load_model, load_image, predict, annotate

model = load_model(CONFIG_PATH, WEIGHTS_PATH)

import torch
import numpy as np
import supervision as sv
import matplotlib.pyplot as plt

device = torch.device("cpu")
torch.set_grad_enabled(False)

CONFIG_PATH = "/content/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py"
CHECKPOINT_PATH = "/content/groundingdino_swint_ogc.pth"

model = load_model(
    CONFIG_PATH,
    CHECKPOINT_PATH,
    device=device
)

model.eval()
print("Model loaded on CPU successfully")

IMAGE_PATH = "/content/aphid1.jpg"

TEXT_PROMPT = "aphid"
BOX_THRESHOLD = 0.35
TEXT_THRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_THRESHOLD,
    text_threshold=TEXT_THRESHOLD,
    device=device
)

annotated_frame = annotate(
    image_source=image_source,
    boxes=boxes,
    logits=logits,
    phrases=phrases
)

sv.plot_image(annotated_frame, (16, 16))

for u in ['aphid', 'whitefly']:
  for i in range(1, 5):
    IMAGE_PATH = f"/content/{u}{i}.jpg"


    TEXT_PROMPT = f"{u}"
    BOX_TRESHOLD = 0.35
    TEXT_TRESHOLD = 0.25

    image_source, image = load_image(IMAGE_PATH)

    boxes, logits, phrases = predict(
        model=model,
        image=image,
        caption=TEXT_PROMPT,
        box_threshold=BOX_THRESHOLD,
        text_threshold=TEXT_THRESHOLD,
        device=device
    )
    annotated_frame = annotate(
        image_source=image_source,
        boxes=boxes,
        logits=logits,
        phrases=phrases
    )

    sv.plot_image(annotated_frame, (16, 16))